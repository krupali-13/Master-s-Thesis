{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from dtaidistance import dtw\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering for first 6 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Score: 1.4370608363900756, Silhouette Score: 0.12032298331837392, DTW Variance: 3.2519800324016126\n",
      "Final labels:  [1 0 0 0 0 1]\n",
      "Cluster centroids:  [[[0.3626918 ]\n",
      "  [0.13862752]\n",
      "  [0.13862752]\n",
      "  ...\n",
      "  [0.35665761]\n",
      "  [0.41610647]\n",
      "  [0.01775309]]\n",
      "\n",
      " [[0.62397984]\n",
      "  [0.94274809]\n",
      "  [0.94274809]\n",
      "  ...\n",
      "  [0.18917071]\n",
      "  [0.84536082]\n",
      "  [0.81232295]]]\n"
     ]
    }
   ],
   "source": [
    "# Define the function to compute DTW Within-Cluster Variance\n",
    "def compute_dtw_within_cluster_variance(data, labels, centroids):\n",
    "    clusters_dtw_variance = []\n",
    "    for cluster_id in set(labels):\n",
    "        cluster_indices = np.where(labels == cluster_id)[0]\n",
    "        cluster_data = data[cluster_indices]\n",
    "        centroid = centroids[cluster_id]\n",
    "        dtw_distances = [dtw.distance(cluster_data[i], centroid) for i in range(len(cluster_data))]\n",
    "        clusters_dtw_variance.append(np.mean(dtw_distances))\n",
    "    return np.mean(clusters_dtw_variance)\n",
    "\n",
    "# Get data \n",
    "cwd = os.path.normpath(os.path.dirname(os.getcwd()))\n",
    "df = pd.read_csv(cwd+'/data/2feature_engineering_data/df_with_final_features.csv', index_col='Date')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Only consider data for the first 5 users\n",
    "columns_to_keep = []\n",
    "for column_name in df.columns:\n",
    "    if column_name.startswith('User') and column_name[4:].isdigit():\n",
    "        user_number = int(column_name[4:])\n",
    "        if 1 <= user_number <= 6:  # Change to 5 users\n",
    "            columns_to_keep.append(column_name)\n",
    "\n",
    "filtered_df = df[columns_to_keep]\n",
    "filtered_df.reset_index(inplace=True)\n",
    "\n",
    "# Preprocessing\n",
    "filtered_df = filtered_df[(filtered_df['Date'].dt.month == 3) & (filtered_df['Date'].dt.year == 2013)]\n",
    "data_array = np.array(filtered_df.T.drop('Date').values)\n",
    "data_array = MinMaxScaler().fit_transform(data_array)\n",
    "data_array_2d = data_array.reshape(data_array.shape[0], -1)\n",
    "\n",
    "# Specify the maximum number of clusters you want to consider\n",
    "# max_clusters = 2\n",
    "cluster_count = 2  # Specify the desired number of clusters\n",
    "\n",
    "kmeans = TimeSeriesKMeans(n_clusters=cluster_count, verbose=False, random_state=42, metric=\"dtw\")\n",
    "labels = kmeans.fit_predict(data_array)\n",
    "np.savetxt(f'../evaluations/clusters_KMeansNew{cluster_count}_dtw.csv', labels, delimiter=\",\")\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Compute DTW Within-Cluster Variance\n",
    "dtw_variance = compute_dtw_within_cluster_variance(data_array, labels, centroids)\n",
    "\n",
    "# Evaluate the clustering performance using all scores\n",
    "db_score = davies_bouldin_score(data_array, labels)\n",
    "sil_score = silhouette_score(data_array, labels)\n",
    "print(f\"Davies-Bouldin Score: {db_score}, Silhouette Score: {sil_score}, DTW Variance: {dtw_variance}\")\n",
    "\n",
    "print(\"Final labels: \", labels)\n",
    "print(\"Cluster centroids: \", centroids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering for 30 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Score: 1.8730964723651322, Silhouette Score: 0.042810982720721126, DTW Variance: 1.9605766620467513\n",
      "Final labels:  [5 0 2 2 1 4 0 4 3 1 0 1 4 3 1 1 1 4 2 4 1 1 0 0 1 1 2 1 2 0]\n",
      "Cluster centroids:  [[[0.04689709]\n",
      "  [0.07786725]\n",
      "  [0.14781002]\n",
      "  ...\n",
      "  [0.04848416]\n",
      "  [0.12180112]\n",
      "  [0.07022518]]\n",
      "\n",
      " [[0.01708401]\n",
      "  [0.16148332]\n",
      "  [0.42328509]\n",
      "  ...\n",
      "  [0.20050317]\n",
      "  [0.58654335]\n",
      "  [0.15516239]]\n",
      "\n",
      " [[0.30532011]\n",
      "  [0.34342972]\n",
      "  [0.61141321]\n",
      "  ...\n",
      "  [0.5464541 ]\n",
      "  [0.5464541 ]\n",
      "  [0.65168773]]\n",
      "\n",
      " [[0.38987891]\n",
      "  [1.        ]\n",
      "  [0.96701121]\n",
      "  ...\n",
      "  [0.40982287]\n",
      "  [0.58616011]\n",
      "  [0.51118421]]\n",
      "\n",
      " [[0.30768322]\n",
      "  [0.443817  ]\n",
      "  [0.43227624]\n",
      "  ...\n",
      "  [0.05876   ]\n",
      "  [0.09146159]\n",
      "  [0.17098031]]\n",
      "\n",
      " [[0.04418395]\n",
      "  [0.30084746]\n",
      "  [0.73170732]\n",
      "  ...\n",
      "  [0.13768116]\n",
      "  [0.17774763]\n",
      "  [0.99342105]]]\n"
     ]
    }
   ],
   "source": [
    "# Define the function to compute DTW Within-Cluster Variance\n",
    "def compute_dtw_within_cluster_variance(data, labels, centroids):\n",
    "    clusters_dtw_variance = []\n",
    "    for cluster_id in set(labels):\n",
    "        cluster_indices = np.where(labels == cluster_id)[0]\n",
    "        cluster_data = data[cluster_indices]\n",
    "        centroid = centroids[cluster_id]\n",
    "        dtw_distances = [dtw.distance(cluster_data[i], centroid) for i in range(len(cluster_data))]\n",
    "        clusters_dtw_variance.append(np.mean(dtw_distances))\n",
    "    return np.mean(clusters_dtw_variance)\n",
    "\n",
    "# Get data \n",
    "cwd = os.path.normpath(os.path.dirname(os.getcwd()))\n",
    "df = pd.read_csv(cwd+'/data/2feature_engineering_data/df_with_final_features.csv', index_col='Date')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Only consider data for the first 5 users\n",
    "columns_to_keep = []\n",
    "for column_name in df.columns:\n",
    "    if column_name.startswith('User') and column_name[4:].isdigit():\n",
    "        user_number = int(column_name[4:])\n",
    "        if 1 <= user_number <= 30:  # Change to 30 users\n",
    "            columns_to_keep.append(column_name)\n",
    "\n",
    "filtered_df = df[columns_to_keep]\n",
    "filtered_df.reset_index(inplace=True)\n",
    "\n",
    "# Preprocessing\n",
    "filtered_df = filtered_df[(filtered_df['Date'].dt.month == 3) & (filtered_df['Date'].dt.year == 2013)]\n",
    "data_array = np.array(filtered_df.T.drop('Date').values)\n",
    "data_array = MinMaxScaler().fit_transform(data_array)\n",
    "data_array_2d = data_array.reshape(data_array.shape[0], -1)\n",
    "\n",
    "# Specify the maximum number of clusters you want to consider\n",
    "# max_clusters = 2\n",
    "cluster_count = 6  # Specify the desired number of clusters\n",
    "\n",
    "kmeans = TimeSeriesKMeans(n_clusters=cluster_count, verbose=False, random_state=42, metric=\"dtw\")\n",
    "labels = kmeans.fit_predict(data_array)\n",
    "np.savetxt(f'../evaluations/clusters_KMeansNew{cluster_count}_dtw.csv', labels, delimiter=\",\")\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Compute DTW Within-Cluster Variance\n",
    "dtw_variance = compute_dtw_within_cluster_variance(data_array, labels, centroids)\n",
    "\n",
    "# Evaluate the clustering performance using all scores\n",
    "db_score = davies_bouldin_score(data_array, labels)\n",
    "sil_score = silhouette_score(data_array, labels)\n",
    "print(f\"Davies-Bouldin Score: {db_score}, Silhouette Score: {sil_score}, DTW Variance: {dtw_variance}\")\n",
    "\n",
    "print(\"Final labels: \", labels)\n",
    "print(\"Cluster centroids: \", centroids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
